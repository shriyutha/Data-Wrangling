{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WRANGLE AND ANALYZE DATA:\n",
    "\n",
    "INTRODUCTION:\n",
    "\n",
    "    The dataset that I will be wrangling (and analyzing and visualizing) is WeRateDogs, tweet archive of Tweeter account using python (and it's libraries).\n",
    "\n",
    "    And will document wrangling efforts in Jupyter Notebook.\n",
    "\n",
    "    The WeRateDogs is a Tweeter account, that rates people's dogs with a humorous comment about the dog.\n",
    "\n",
    "    These ratings almost have a denominator of 10.\n",
    "\n",
    "    The numerators always greater than 10. Like 11/10, 15/10, etc...\n",
    "\n",
    "    Because \"they are good dogs Brent.\"  \n",
    "\n",
    "    WeRateDogs has over 4 million followers and recived international media coverage.\n",
    "\n",
    "    WeRateDogs downloaded their Twitter archive and sent it to Udacity via email exclusively for us to use in this project.\n",
    "\n",
    "    This archive contains basic tweet data (tweet ID, timestamp, text, source, expanded_urls, name, etc...) for all 5000+ of their tweet as they stood on Auguest 1, 2017.   \n",
    "\n",
    "    The main goal is to wrangle WeRateDogs Twitter data to create interesting and trustworthy analysis and visualizations.\n",
    "\n",
    "    Need to do addtional gathering, then assesing and cleaning for worthy analysis and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE DATA :\n",
    "\n",
    "ENHANCED TWITTER ARCHIVE:\n",
    "\n",
    "    The WeRateDogs Twitter archive contains basic tweet data for all 5000+ of their tweets, but not everything.\n",
    "\n",
    "    One column the archive does contain though: each tweet's text, which I used to extract rating, dog name, and dog \"stage\" (i.e. doggo, floofer, pupper, and puppo) to make this Twitter archive \"enhanced.\" \n",
    "\n",
    "    We manually downloaded this file manually by clicking the following link: twitter_archive_enhanced.csv\n",
    "\n",
    "\n",
    "\n",
    "Additional Data via the Twitter API:\n",
    "\n",
    "1. Back to the basic-ness of Twitter archives: retweet count and favorite count are two of the notable column omissions. \n",
    "2. Fortunately, this additional data can be gathered by anyone from Twitter's API.\n",
    "3. Well, \"anyone\" who has access to data for the 3000 most recent tweets, at least. Because we have the WeRateDogs Twitter archive and specifically the tweet IDs within it, can gather this data for all 5000+.\n",
    "4. And we are going to query Twitter's API to gather this valuable data.\n",
    "\n",
    "\n",
    "\n",
    "IMAGE PREDICTIONS FILE:\n",
    "\n",
    "    The tweet image predictions, i.e., what breed of dog (or other object, animal, etc.) is present in each tweet according to a neural network.\n",
    "\n",
    "    This file (image_predictions.tsv) hosted on Udacity's servers and we downloaded it programmatically using python Requests library on the following (URL)\n",
    "\n",
    "url = https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv)\n",
    "\n",
    "\n",
    "\n",
    "KEY POINTS :\n",
    "\n",
    "Key points to keep in mind when data wrangling for this project:\n",
    "\n",
    "* We only want original ratings (no retweets) that have images.\n",
    "* Though there are 5000+ tweets in the dataset, not all are dog ratings and some are retweets.\n",
    "* Assessing and cleaning the entire dataset completely would require a lot of time, and is not necessary to practice and demonstrate our skills in data wrangling.\n",
    "* Therefore, the requirements of this project are only to assess and clean at least 8 quality issues and at least 2 tidiness issues in this dataset.\n",
    "* Cleaning includes merging individual pieces of data according to the rules of tidy data.\n",
    "* The fact that the rating numerators are greater than the denominators does not need to be cleaned.\n",
    "his unique rating system is a big part of the popularity of WeRateDogs.\n",
    "* Do not need to gather the tweets beyond August 1st, 2017.\n",
    "\n",
    "\n",
    "\n",
    "Twitter API:\n",
    "\n",
    "    In this project, we will be using Tweepy to query Twitter's API for additional data beyond the data included in the WeRateDogs Twitter archive. \n",
    "\n",
    "    This additional data will include retweet count and favorite count.\n",
    "\n",
    "    Some APIs are completely open, like MediaWiki (accessed via the wptools library). Others require authentication. \n",
    "\n",
    "    The Twitter API is one that requires users to be authorized to use it. This means that before we can run our API querying code, you need to set up our own Twitter application. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "PROJECT DETAILS:\n",
    "\n",
    "our tasks in this project are as follows:\n",
    "\n",
    "Data wrangling, which consists of:\n",
    "\n",
    "    Gathering data\n",
    "\n",
    "    Assessing data\n",
    "\n",
    "    Cleaning data\n",
    "\n",
    "    Storing, analyzing, and visualizing our wrangled data\n",
    "\n",
    "Reporting on 1) our data wrangling efforts and 2) our data analyses and visualizations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "RESOURCES:\n",
    "\n",
    "1. Twitter API\n",
    "\n",
    "2. Files downloaded from Udacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUALITY ISSUES :\n",
    "\n",
    "data:\n",
    "\n",
    "1. [Visual Inspection]: Missing values in 'in_reply_to_status_id', 'in_reply_to_user_id', 'retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp'.\n",
    "2. [Visual Inspection]: The columns 'doggo', 'floofer', 'pupper', 'puppo' have (string) 'None' instead of NaN.\n",
    "3. Programming: Columns 'timestamp' is in object(string).\n",
    "4. Programming: Column 'name' has inaccurate names like a, an, the, this, not, and some lower case words.\n",
    "5. Programming: Columns 'rating_numerator', 'rating_denominator' have values more than 10.\n",
    "6. Programming: Column 'retweeted_status_user_id' has duplicated values.\n",
    "7. Programming: Column 'name' has inaccurate names like O instead of O'Malley (gotto know from 'text').\n",
    "8. [Visual Inspection]: Column 'source' is in html format and contains a tag ' <a '.\n",
    "\n",
    "\n",
    "image_data:\n",
    "\n",
    "9. [Visual Inspection]: 'data' dataframe has 2356 tweets and 'image_data' dataframe has 2075 tweets.\n",
    "10. Programming: Column 'jpg_url' has dulipacted values.\n",
    "\n",
    "\n",
    "tweet_data:\n",
    "\n",
    "11. [Visual Inspection]: Missing tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIDINESS ISSUES :\n",
    "\n",
    "data:\n",
    "\n",
    "1. The columns 'doggo', 'floofer', 'pupper', 'puppo' should be one column.\n",
    "\n",
    "\n",
    "image_data:\n",
    "\n",
    "2. 'image_data' dataframe should be combined to 'data' dataframe.\n",
    "3. Creating two columns 'image_pred'(prediction for the image in the tweet) and 'pred_value' (confidence level of predicted image), and droping 'p1', 'p2', 'p3', 'p1_conf', 'p2_conf', 'p3_conf', 'p1_dog', 'p2_dog', 'p3_dog'.\n",
    "\n",
    "\n",
    "tweet_data:\n",
    "\n",
    "4. 'tweet_data' dataframe should be combined to 'data' dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOLUTIONS FOR THE ANALYSIS :\n",
    "\n",
    "NOTE :\n",
    "    Analyses and Visualizations are based on my wrangling work that I assessed and cleaned according to my knowlegde.\n",
    "    \n",
    "    \n",
    "\n",
    "1. 'df' data frame is created by merging all three data sets (data, image_data, tweet_data).\n",
    "2. 'dog_stages' column is created using melting function and columns 'doggo', 'floofer', 'pupper', 'puppo' is delected.\n",
    "3. Columns 'image_pred'(prediction for the image in the tweet) and 'pred_value' (confidence level of predicted image) are created, and dropped 'p1', 'p2', 'p3', 'p1_conf', 'p2_conf', 'p3_conf', 'p1_dog', 'p2_dog', 'p3_dog'.\n",
    "4. Deleted duplicated rows in column 'retweeted_status_user_id'.\n",
    "5. Dropped columns 'in_reply_to_status_id', 'in_reply_to_user_id', 'retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp' for missing values.\n",
    "6. Removed unwanted tags from column 'source'.\n",
    "7. Changed column 'timestamp' format to datetime.\n",
    "8. Delected lower case words and replaced None value to NaN in 'name' column.\n",
    "9. Deleted duplicated rows in column 'jpg_url'.\n",
    "10. Replaced O'Malley instead of 'O' in column 'name'.\n",
    "11. Changed/replaced NaN instead of 'None' in column 'dog_stages' i.e., 'doggo', 'floofer', 'pupper', 'puppo'.\n",
    "12. Created new column 'dog_rating' using columns 'rating_numerator', 'rating_denominator' for future analysis.\n",
    "13. Changed float datatype to int in column 'favorite_count' and 'retweet_count'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
